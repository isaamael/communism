

## 比对

```shell
#ZH比对
scriptdir=/public/home/xuruiqiang/work/xinpian/script

for i in $(seq 31 66);do
echo "#SBATCH -p arm
#SBATCH --nodes=1
#SBATCH --cpus-per-task=40

refdir=/public/home/xuruiqiang/work/reference/tomato/5.0
rawdatadir=/public/home/xuruiqiang/Dataset/reseq/tomato36/cleandata
bamdir=/public/home/xuruiqiang/work/xinpian/bwa/ZH
scriptdir=/public/home/xuruiqiang/work/xinpian/script/bwa/ZH

bwa mem $refdir/SL5.0.fasta \\
$rawdatadir/ZH${i}_R1.fq.gz \\
$rawdatadir/ZH${i}_R2.fq.gz \\
-t 40 -M -R \"@RG\tID:ZH${i}\tLB:ZH${i}\tPL:ILLUMINA\tSM:ZH${i}\" \\
|samtools view -bS -@ 40 | samtools sort -@ 40 -m 10G \\
-o $bamdir/ZH${i}.sort.bam
samtools index $outputdir/ZH${i}.sort.bam " > /public/home/xuruiqiang/work/xinpian/script/bwa/ZH/ZH${i}.bwa.sh
done

#添加脚本开头,arm节点下提交比对脚本
cd /public/home/xuruiqiang/work/xinpian/script/bwa/ZH
sed -i '1i#!/bin/bash' *.sh
ll | awk '{print "sbatch",$9}' | sed '1d' > total.sh
sed -i '1d' total.sh
sh total.sh
```

```shell
#a比对
for i in $(seq 1 126);do
echo "#SBATCH -p gpu-3090,gpu-v100s
#SBATCH --nodes=1
#SBATCH --cpus-per-task=30

refdir=/public/home/xuruiqiang/work/reference/tomato/5.0
rawdatadir=/public/home/xuruiqiang/Dataset/reseq/xinpian
bamdir=/public/home/xuruiqiang/work/xinpian/bwa/22a
scriptdir=/public/home/xuruiqiang/work/xinpian/script/bwa/22a

bwa mem \$refdir/SL5.0.fasta \\
\$rawdatadir/a${i}_R1.fq.gz \\
\$rawdatadir/a${i}_R2.fq.gz \\
-t 40 -M -R \"@RG\tID:a${i}\tLB:a${i}\tPL:ILLUMINA\tSM:a${i}\" \\
|samtools view -bS -@ 30 | samtools sort -@ 30 -m 5G \\
-o \$bamdir/a${i}.sort.bam
samtools index \$bamdir/a${i}.sort.bam " > /public/home/xuruiqiang/work/xinpian/script/bwa/22a/a${i}.bwa.sh
done

#添加脚本开头,arm节点下提交比对脚本
cd /public/home/xuruiqiang/work/xinpian/script/bwa/22a
sed -i '1i#!/bin/bash' *.sh
ll | awk '{print "sbatch",$9}' | sed '1d' > total.sh
sed -i '1d' total.sh
sh total.sh
```



## call snp

```shell
#ZH脚本写出
for i in $(seq 31 66);do
echo "#SBATCH --partition=gpu-3090,gpu-v100s
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=40
#SBATCH --gpus=1

refdir=/public/home/xuruiqiang/work/reference/tomato/5.0
bamdir=/public/home/xuruiqiang/work/xinpian/bwa/ZH
dvdir=/public/home/xuruiqiang/work/xinpian/deep/ZH
tmpdir=/public/home/xuruiqiang/work/xinpian/tmp/dvtmp
scriptdir=/public/home/xuruiqiang/work/xinpian/script/dv

/public/software/singularity/singularity-3.5.2/bin/singularity exec \\
--nv /public/software/singularity/singularity-3.5.2/docker-images/deepvariant-gpu.1.4.0.sif \\
/opt/deepvariant/bin/run_deepvariant \\
--model_type=WGS \\
--ref=$refdir/SL5.0.fasta \\
--reads=$bamdir/ZH${i}.sort.bam \\
--output_vcf=$dvdir/vcf/ZH${i}.vcf.gz \\
--output_gvcf=$dvdir/gvcf/ZH${i}.gvcf.gz \\
--intermediate_results_dir=$tmpdir/ZH${i} \\
--num_shards=40 " > /public/home/xuruiqiang/work/xinpian/script/dv/ZH/ZH${i}.dv.sh
done

#添加脚本开头,gpu节点下提交比对脚本
cd /public/home/xuruiqiang/work/xinpian/script/dv/ZH
sed -i '1i#!/bin/bash' *.sh
ll | awk '{print "sbatch",$9}' | sed '1d' > total.sh
sed -i '1d' total.sh
sh total.sh
```

```shell
#22a脚本
for i in $(seq 1 126);do
echo "#SBATCH --partition=gpu-3090,gpu-v100s
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=30
#SBATCH --gpus=1

refdir=/public/home/xuruiqiang/work/reference/tomato/5.0
bamdir=/public/home/xuruiqiang/work/xinpian/bwa/22a
dvdir=/public/home/xuruiqiang/work/xinpian/deep/22a
tmpdir=/public/home/xuruiqiang/work/xinpian/tmp/dvtmp
scriptdir=/public/home/xuruiqiang/work/xinpian/script/dv

/public/software/singularity/singularity-3.5.2/bin/singularity exec \\
--nv /public/software/singularity/singularity-3.5.2/docker-images/deepvariant-gpu.1.4.0.sif \\
/opt/deepvariant/bin/run_deepvariant \\
--model_type=WGS \\
--ref=\$refdir/SL5.0.fasta \\
--reads=\$bamdir/a${i}.sort.bam \\
--output_vcf=\$dvdir/vcf/a${i}.vcf.gz \\
--output_gvcf=\$dvdir/gvcf/a${i}.gvcf.gz \\
--intermediate_results_dir=\$tmpdir/a${i} \\
--num_shards=30 " > /public/home/xuruiqiang/work/xinpian/script/dv/22a/a${i}.dv.sh
done

#添加脚本开头,gpu节点下提交比对脚本
cd /public/home/xuruiqiang/work/xinpian/script/dv/22a
sed -i '1i#!/bin/bash' *.sh
ll | awk '{print "sbatch",$9}' | sed '1d' > total.sh
sed -i '1d' total.sh
sh total.sh
```



## 检查文件数目和完整性

```shell
#按照以下方式依次检查bam文件和vcf文件的个数
#手动检查bam和vcf文件的大小
#对有问题的样本单独重新提交

cd /public/home/xuruiqiang/work/xinpian/bwa/22a
for i in $(seq 1 130); do
if [ ! -f "a${i}.sort.bam" ];then
echo "${i} not exist" >> check.txt 
fi
done
```



## gvcf文件合并

```shell
#写出glnexus合并输出的gvcf文件脚本
echo "#SBATCH -p gpu-3090,gpu-v100s
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=40
#SBATCH --gpus=1

tmpdir=/public/home/xuruiqiang/work/xinpian/tmp/merge/
dvdir=/public/home/xuruiqiang/work/xinpian/deep/merge

/public/software/singularity/singularity-3.5.2/bin/singularity \\
run ~/software/singularity/glnexus_v1.4.1.sif glnexus_cli \\
--dir \$tmpdir/tmp \\
--config DeepVariantWGS --threads 40 \\
\$dvdir/gvcf/*.gvcf.gz > \$dvdir/merge.bcf
bcftools view \$dvdir/merge.bcf -O z -o \$dvdir/merge.vcf.gz " > /public/home/xuruiqiang/work/xinpian/deep/merge.sh

#arm节点下提交合并脚本
sbacth /public/home/xuruiqiang/work/xinpian/deep/mergeZH.sh
```



## snp过滤



```shell
#!/bin/bash
#SBATCH -p big,low

#首先过滤双等位和最大缺失
vcftools --gzvcf merge.vcf.gz --recode --recode-INFO-all --stdout --min-alleles 2 --max-alleles 2 --max-missing 0.25 > merge.filter1.vcf

#拆分染色体
for i in $(seq 1 12);do
vcftools --vcf merge.filter1.vcf --chr ${i} --recode --recode-INFO-all --stdout > ../chr/chr${i}.vcf
done
```

```python
#python脚本提取每个染色体上每个位点的平均深度和变异系数
#以chr1为例,获得统计值

import os
import numpy as np
os.chdir("/public/home/xuruiqiang/work/xinpian/deep/merge/chr")

for chr in range(1,12):
    fw1=open("stat"+str(chr)+".txt","w")
    print("aveD","cvD",sep="\t",file=fw1)
    for line in open(file="chr"+str(chr)+".sv.vcf"):
        block=line.split("\t")
        if "POS" in line or line.startswith("#"):
            #print(line,end="",file=fw1)
            continue
        else:
            #print(line,file=fw1)
            sumD=0
            list1=[]
            for i in range(9,165):
                list1.append(int(block[i].split(":")[1]))
            sumD=sum(list1)
            stdD=np.std(list1)
            aveD=sumD/157
            cvD=stdD/aveD
            #print(list1)
            print(aveD,cvD,sep="\t",file=fw1)
            #if cvD<0.8 and 1.905<aveD<10.795:
            #print(line,end="",file=fw2)
fw1.close()
#fw2.close()
```



### depth为平均depth的0.3倍-1.7倍，最低depth>5

### 手动确认使平均depth符合泊松分布的CV

### 每条染色体单独过滤

![image-20221009145858140](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20221009145858140.png)

![image-20221009150018690](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20221009150018690.png)



### 分染色体过滤

```python
#利用确定的depth和CV分染色体进行过滤
#chr1的python脚本为例

import os
import os 
import pandas as pd
import numpy as np
import re

os.chdir("/public/home/xuruiqiang/work/xinpian/deep/merge/chr")

#fw1=open("stat.txt","w")
fw2=open("chr1.filter.vcf","w")
#print("sumD","aveD","stdD","cvD",sep="\t",file=fw1)
for line in open("chr1.vcf","r"):
    block=line.split("\t")
    if line.startswith("#"):
        print(line,end="",file=fw2) 
        continue
    else:
        #print(line,file=fw1)
        sumD=0
        list1=[]
        for i in range(9,165):
            list1.append(int(block[i].split(":")[1]))
        sumD=sum(list1)
        stdD=np.std(list1)
        aveD=sumD/157
        cvD=stdD/aveD
        #print(list1)
        #print(sumD,aveD,stdD,cvD,sep="\t",file=fw1)
        if cvD<0.4 and 5.19<aveD<29.41:
            print(line,end="",file=fw2)
#fw1.close()
fw2.close()
```



### 合并分开的12条染色体vcf

```shell
#!/bin/bash
#SBATCH -p gpu-3090,gpu-v100s

#for i in $(seq 2 12);do
#sed -i '1,33d' chr${i}.filter.vcf 
#cat chr${i}.filter.vcf >> merge.filter.vcf
#done

#利用bcftools concat功能合并
bcftools concat -f file -Ov -o merge.filter.vcf
```



## SV分型

paragraph通过conda安装

### 使用idxdepth准备输入文件

```shell
#!/bin/bash
#SBATCH -p gpu-3090,gpu-v100s

refdir=/public/home/xuruiqiang/work/reference/tomato/5.0
bamdir=/public/home/xuruiqiang/work/xinpian/bwa/
#使用idxdepth脚本循环计算每个bam的深度和平均读长
for i in $(seq 1 122);do
idxdepth -b $bamdir/22a/a${i}.sort.bam -r $refdir/SL5.0.fasta -o $bamdir/22a/a${i}.json
idxdepth -b $bamdir/ZH/ZH${i}.sort.bam -r $refdir/SL5.0.fasta -o $bamdir/ZH/ZH${i}.json
#解读json文件并提取值
adep=$(jq -r .autosome.depth $bamdir/22a/a${i}.json)
alen=$(jq -r .read_length $bamdir/22a/a${i}.json) 
apath=$(jq -r .bam_path $bamdir/22a/a${i}.json)
ZHdep=$(jq -r .autosome.depth $bamdir/ZH/ZH${i}.json)
ZHlen=$(jq -r .read_length $bamdir/ZH/ZH${i}.json) 
ZHpath=$(jq -r .bam_path $bamdir/ZH/ZH${i}.json)
idxpath=/public/home/xuruiqiang/work/xinpian/bwa/
#写出每个样品的sample.list信息
if [ -e "$bamdir/22a/a${i}.json" ];then
echo -e "id\tpath\tidxdepth" >> /public/home/xuruiqiang/work/xinpian/sv/paragraph/samplist/a${i}.list
echo -e "a${i}\t$apath\t$idxpath/22a/a${i}.json" >> /public/home/xuruiqiang/work/xinpian/sv/paragraph/samplist/a${i}.list
fi
if [ -e "$bamdir/ZH/ZH${i}.json" ];then
echo -e "id\tpath\tidxdepth" >> /public/home/xuruiqiang/work/xinpian/sv/paragraph/samplist/ZH${i}.list
echo -e "ZH${i}\t$ZHpath\t$idxpath/ZH/ZH${i}.json" >> /public/home/xuruiqiang/work/xinpian/sv/paragraph/samplist/ZH${i}.list
fi
done
```



### 分型

```shell
#写出每个样品的单独分型脚本，并提交

for i in $(seq 1 122);do
echo "#!/bin/bash
#SBATCH -p gpu-3090,gpu-v100s
#SBATCH --ntasks-per-node=40
#SBATCH --gpus=2
multigrmpy.py -i /home/zhouyao/final_results/01_data/16_sv_paragraph/SV.paragraph.vcf \
-m /public/home/xuruiqiang/work/xinpian/sv/paragraph/samplist/a${i}.list \
-r /public/home/xuruiqiang/work/reference/tomato/5.0/SL5.0.fasta \
-o /public/home/xuruiqiang/work/xinpian/sv/paragraph/genotype/a${i} \
--threads 40 " > /public/home/xuruiqiang/work/xinpian/sv/paragraph/getgenotype/a${i}.sv.sh

echo "#!/bin/bash
#SBATCH -p gpu-3090,gpu-v100s
#SBATCH --ntasks-per-node=40
#SBATCH --gpus=2
multigrmpy.py -i /home/zhouyao/final_results/01_data/16_sv_paragraph/SV.paragraph.vcf \
-m /public/home/xuruiqiang/work/xinpian/sv/paragraph/samplist/ZH${i}.list \
-r /public/home/xuruiqiang/work/reference/tomato/5.0/SL5.0.fasta \
-o /public/home/xuruiqiang/work/xinpian/sv/paragraph/genotype/ZH${i} \
--threads 40 " > /public/home/xuruiqiang/work/xinpian/sv/paragraph/getgenotype/ZH${i}.sv.sh
done
```



#### 使用for循环检查每个样品的genotypes.vcf.gz文件是否存在及完整

#### 每个vcf创建tbi索引

```shell
#!/bin/bash
#SBATCH -p gpu-3090,gpu-v100s
for i in $(seq 1 121);do
tabix -f a${i}/genotypes.vcf.gz
tabix -f ZH${i}/genotypes.vcf.gz
done
```



## 分别合并a群体，ZH群体和a+ZH群体的sv.vcf文件

```shell
#!/bin/bash
#SBATCH -p gpu-3090,gpu-v100s
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=40
#SBATCH --gpus=1

#通过提供不同file列表合并vcf

bcftools merge --file-list allfile -Oz -o all.vcf.gz
bcftools merge --file-list afile -Oz -o a.vcf.gz
bcftools merge --file-list zhfile -Oz -o zh.vcf.gz
```

------



## 挑选候选位点

### 候选区间提取

```shell
#!/bin/bash
#SBATCH -p gpu-3090,gpu-v100s

refdir=/public/home/xuruiqiang/work/reference/tomato/5.0
region=/public/home/xuruiqiang/work/xinpian/site/region
#提取gene位置
grep -w "gene" $refdir/SL5.0.gff3 | grep -v -w "0" | awk -v OFS="\t" '{print $1,$4,$5,$7,$9}' > gene.anno.bed
#提取exon位置
grep -w "exon" $refdir/SL5.0.gff3 | grep -v -w "0" | awk -v OFS="\t" '{print $1,$4,$5,$7,$9}' > exon.anno.bed
#提取promoter位置
grep -w "+" gene.anno.bed | awk -v OFS="\t" '{print $1,$2-2000,$2,$5}' > zheng.bed
grep -w "-" gene.anno.bed | awk -v OFS="\t" '{print $1,$3,$3+2000,$5}' > fu.bed
cat zheng.bed fu.bed | bedtools sort -i - | bedtools subtract -a gene.anno.bed -b - -A > promoter.anno.bed
```



### snp和indel

```shell
#!/bin/bash
#SBATCH -p gpu-3090,gpu-v100s

vcfdir=/public/home/xuruiqiang/work/xinpian/deep/merge/chr
#分别过滤a群体和ZH群体的mac值
vcftools --vcf $vcfdir/merge.filter.vcf --mac 3 --keep $vcfdir/asample.list --recode --recode-INFO-all --stdout > amac.vcf
vcftools --vcf $vcfdir/merge.filter.vcf --mac 3 --keep $vcfdir/ZHsample.list --recode --recode-INFO-all --stdout > ZHmac.vcf
#筛选两个群体过滤后相同的位点
vcftools --vcf amac.vcf --diff ZHmac.vcf --diff-site --out aZH
grep -w "B" aZH.diff.sites_in_files > both.site
#通过位点提取vcf文件
vcftools --vcf $vcfdir/merge.filter.vcf --bed both.site --recode --recode-INFO-all --stdout > aZHmac.vcf
#分离snp和indel
vcftools --vcf aZHmac.vcf --keep-only-indels --recode --recode-INFO-all --out aZHmac.indel.vcf
vcftools --vcf aZHmac.vcf --remove-indels --recode --recode-INFO-all --out aZHmac.snp.vcf
```



### sv

```shell
#!/bin/bash
#SBATCH -p gpu-3090,gpu-v100s
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=40
#SBATCH --gpus=1
#过滤a群体sv
vcftools --gzvcf a.vcf.gz --mac 2 --recode --recode-INFO-all --stdout > a.filter.vcf.gz
#过滤ZH群体sv
vcftools --gzvcf zh.vcf.gz --mac 2 --recode --recode-INFO-all --stdout > ZH.filter.vcf.gz
#获得共同位点
vcftools --gzvcf a.filter.vcf.gz --gzdiff ZH.filter.vcf.gz --diff-site --out sv
grep -w "B" sv.diff.sites_in_files > both.site
#提取共同sv，7w行
vcftools --gzvcf all.vcf.gz --bed both.site --recode --recode-INFO-all --stdout > aZHmac.sv.vcf
```



## erro

```shell
vcftools --zvcf aZHmac.sv.vcf --gzdiff sv.array.vcf.gz --diff-site --out 7w2
grep -w "B" 7w2.diff.sites_in_files > both.sv.site #9620
grep -w "1" 7w2.diff.sites_in_files > 7w.sv.site   #68159
grep -w "2" 7w2.diff.sites_in_files > 2w.sv.site   #12768
zcat sv.array.vcf.gz | wc -l   #20978
wc -l aZHmac.sv.vcf            #78884

```





## 芯片设计位点的获取

```python
import os
import re
from bisect import bisect_left
from collections import defaultdict
import random
from typing import Any

os.chdir(r'D:\work\xinpian\site\test')

fw1=open("all.pos.exon","w")
fw2=open("uniq.pos.exon","w")
fw3=open("all.pos.gene","w")
fw4=open("uniq.pos.gene","w")
fw5=open("no_hit_gene","w")

#dic1：记录染色体和开始位置的对应
#dict2：记录开始位置和基因id的对应
#dict3：记录开始和结束的位置
#dict4：记录所有符合条件的基因-位点位置
#dict5：记录仅保留一个时选择的基因-位点位置
#set1：存储所有的基因id
#list1：每个基因位置按照gff文件顺序排列
dcitCHR={}

dict1=defaultdict(list)
dict2: defaultdict[Any, list]=defaultdict(list)
dict3=defaultdict(list)
dict4=defaultdict(list)
dict5=defaultdict(list)
list1=[]
list2=[]
listid=[]
set1= set()
gdict1=defaultdict(list)
gdict2=defaultdict(list)
gdict3=defaultdict(list)
gdict4=defaultdict(list)
gdict5=defaultdict(list)
glist1=[]
glist2=[]
glistid=[]
gset1= set()
num1=0
num2=0
num3=0
num4=0
#循环读入外显子的bed文件
for line in open("test.exon.bed","r"):
    block=line.split("\t")
    chrom=block[0]
    start=block[1]
    end=block[2]
    #替换id列的书写规则
    id=re.sub('\.\d', '', block[4].replace('Parent=', ''))
    set1.add(id.strip()) #记录所有基因的id
    dictCHR[id.strip()]=chrom.strip()
    dict1[chrom].append(int(start))
    dict2[start].append(id.strip())
    dict3[start].append(end)
    #分染色体写入起始和终止位置
    exec(f'list{chrom}.append(int(start))')
    exec(f'list{chrom}.append(int(end))')
    num1+=1
#循环读入基因的bed文件
for line in open("test.gene.bed","r"):
    gblock=line.split("\t")
    gchrom=gblock[0]
    gstart=gblock[1]
    gend=gblock[2]
    #替换基因id书写规则
    gid = re.sub(r'ID=(.*);Name=.*', r'\1', gblock[4])
    gid = re.sub("G", "T", gid)
    gset1.add(gid.strip())
    gdict1[gchrom].append(int(gstart))
    gdict2[gstart].append(gid.strip())
    gdict3[gstart].append(gend)
    #分染色体写出起始和终止位置
    exec(f'glist{gchrom}.append(int(gstart))')
    exec(f'glist{gchrom}.append(int(gend))')
    num2+=1
#循环读入vcf文件
for line in open("test.snp.vcf", "r"):
    block = line.split("\t")
    schr=block[0]
    pos = block[1]
    #使用二分法判断起始位置是否处在一个exon/gene的区域内
    if bisect_left((locals()[f'list{schr}']), int(pos)) % 2 != 0:
        #提取落入的第几个区域
        a: int=bisect_left((locals()[f'list{schr}']), int(pos))
        #根据起始位置提取这个基因的id
        print(dict2.get(str(locals()[f'list{schr}'][(a-1)]))[0],str(schr),int(pos),file=fw1,sep="\t")
        #写出一个符合条件的区域起始位置和site位置的字典
        dict4[str((dict2.get(str((locals()[f'list{schr}'])[(a-1)])))[0])].append(pos)
    elif bisect_left((locals()[f'glist{schr}']), int(pos)) % 2 != 0:
        a: int=bisect_left((locals()[f'glist{schr}']), int(pos))
        print(dict2.get(str(locals()[f'glist{schr}'][(a-1)]))[0], int(pos),file=fw3,sep="\t")
        gdict4[str((gdict2.get(str((locals()[f'glist{schr}'])[(a-1)])))[0])].append(pos)
    num3+=1
#for k in set1: #遍历每一个基因id
#    #判断这个基因id所处的染色体位置
#    if k[5] == "0": 
#        kchr = k[6]
#    else:
#        kchr = (k[5] + k[6])
for k in dictCHR.keys():
    kchr=dictCHR.get(k)
    #print(kchr)
    #从对应的染色体文件中提取
    if dict4.get(k):
        #随机选择一个基因id-位点pos
        pos2=random.choice(dict4.get(k))
        #保留随机选择的结果
        dict5[k].append(pos2)
        #写出 
        print(k,kchr,pos2,file=fw2,sep="\t")
    elif gdict4.get(k):
        pos2=random.choice(gdict4.get(k))
        gdict5[k].append(pos2)
        print(k,kchr,pos2,file=fw4,sep="\t")
    else:
        #没有命中查询就写出基因id
        print(k,file=fw5)
    num4+=1

print(num1,num2,num3,num4)

fw1.close()
fw2.close()
fw3.close()
fw4.close()
fw5.close()
```

```python
#按照优先顺序，循环取出位点的结果
import os
os.chdir(r'/public/home/xuruiqiang/work/xinpian/site/site')

fw1=open("sv.list","w")
fw2=open("indel.list","w")
fw3=open("snp.list","w")
fw4=open("sv.promoter.list","w")
fw5=open("indel.promoter.list","w")
fw6=open("snp.promoter.list","w")

gene=[]
svgene=[]
indelgene=[]
snpgene=[]

psvgene=[]
pindelgene=[]
psnpgene=[]

for line in open("gene.list","r"):
    gene.append(line.strip())

for line in open("sv.pos","r"):
    gene1=line.split("\t")[0]
    if gene1 in gene:
        print("sv",line,file=fw1,sep="\t",end="")
        svgene.append(gene1.strip())

for line in open("indel.pos","r"):
    gene2=line.split("\t")[0]
    if gene2 in gene and gene2 not in svgene:
        print("indel",line,file=fw2,sep="\t",end="")
        indelgene.append(gene2.strip())

for line in open("snp.pos","r"):
    gene3=line.split("\t")[0]
    if gene3 in gene and gene3 not in svgene and gene3 not in indelgene:
        print("snp",line,file=fw3,sep="\t",end="")
        snpgene.append(gene3.strip())

for line in open("sv.union.pos.promoter","r"):
    genep1=line.split("\t")[0]
    if genep1 in gene:
        print("sv",line,file=fw4,sep="\t",end="")
        psvgene.append(genep1.strip())

for line in open("indel.union.pos.promoter","r"):
    genep2=line.split("\t")[0]
    if genep2 in gene and genep2 not in svgene:
        print("indel",line,file=fw5,sep="\t",end="")
        pindelgene.append(genep2.strip())

for line in open("snp.union.pos.promoter","r"):
    genep3=line.split("\t")[0]
    if genep3 in gene and genep3 not in psvgene and genep3 not in pindelgene:
        print("snp",line,file=fw6,sep="\t",end="")
        psnpgene.append(genep3)

fw1.close()
fw2.close()
fw3.close()
fw4.close()
fw5.close()
fw6.close()
```



### 从原始vcf文件中提取芯片设计需要的格式

```shell
#!/bin/bash
#SBATCH -p gpu-3090
#使用shell获得基本的结果
vcftools --vcf snp.vcf --exclude-positions out.site --recode --recode-INFO-all --stdout > snp.out.vcf
#主要fa文件需要按照vcf文件的顺序排列，检查行数必须一致
bedtools getfasta -fi /public/home/xuruiqiang/work/reference/tomato/5.0/SL5.0.fasta -bed snp.bed -fo snp200.fa
bedtools getfasta -fi /public/home/xuruiqiang/work/reference/tomato/5.0/SL5.0.fasta -bed indel.bed -fo indel200.fa
paste snp.list snpfa > snp.f1.result
paste indel.list indelfa > indel.result
```



```python
#python脚本修改文件以保证符合格式要求
import os
from collections import defaultdict
os.chdir(r"/public/home/xuruiqiang/work/xinpian/10-11")
#fw1=open("new.snp.bed","w")
fw2=open("snpfa","w")
fw3=open("indelfa","w")
fw4=open("snp.f2.result","w")
fw5=open("indel.f2.result","w")
#dict1=defaultdict(list)
#for line in open("chr.len","r"):
#    chrom=line.split("\t")[0]
#    length=line.split("\t")[1]
#    dict1[chrom].append(length)
#for line in open("snp.bed","r"):
#    block=line.split("\t")
#    bchr=block[0]
#    if int(block[1]) < 0:
#        block[1]=str(0)
#    if int(block[1]) > int(dict1.get(bchr)[0]):
#        block[1]=dict1.get(bchr)
#    print(block[0],block[1],block[2],file=fw1,sep="\t",end="")
#fw1.close()

#清除fa文件的>行
for line in open("snp200.fa","r"):
    if line.startswith(">"):
        continue
    else:
        print(line,end="",file=fw2)
fw2.close()#for line in open("indel200.fa","r"):
    if line.startswith(">"):
        continue
    else:
        print(line,end="",file=fw3)
fw3.close()
#命名一个/和0的字符串
a=str(r'/')
c="0"
#循环读入结果
for line in open("snp.result","r"):
    block=line.split("\t")
    #把第199个碱基用指定的格式写出
    b=(block[5][0:198]+'['+block[3]+a+block[4]+']'+block[5][200:401]).strip()
    #line=line.replace(block[5][199],'['+block[3]+a+block[4]+']')
    print(block[0],block[1],block[2],block[3].strip(),block[4],b,0,sep="\t",file=fw4)
fw4.close()
for line in open("indel.result","r"):
    block=line.split("\t")
    #把从199-indel长度的碱基按照指定格式写出
    b=(block[6][0:198]+'['+block[4]+a+block[5]+']'+block[6][(199+len(block[4])):401]).strip()
    #line=line.replace(block[5][199],'['+block[3]+a+block[4]+']')
    print(block[0],block[1],block[2],block[3],block[4],block[5],b,0,sep="\t",file=fw5)
fw5.close()
```

